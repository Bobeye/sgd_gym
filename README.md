# sgd_gym

Evaluating gradient-based optimization metrics (currently support ["SGD", "Momentum", "Nesterov", "Adagrad", "Adadelta", "RMSprop", "Adam"]) with unit testing functions (currently support ["Beale", "Booth", "McCormick"]).

For more information, please refer to:

[1] https://en.wikipedia.org/wiki/Test_functions_for_optimization

[2] http://tiao.io/notes/visualizing-and-animating-optimization-algorithms-with-matplotlib/

[3] http://ruder.io/optimizing-gradient-descent/index.html#adagrad

![alt text](images/Beale.png "Beale function")
![alt text](images/Beale_gradient.png "Beale_gradient function")
![alt text](images/Beale_0.png "Beale_0")
![alt text](images/Beale_1.png "Beale_1")

![alt text](images/Booth.png "Booth function")
![alt text](images/Booth_gradient.png "Booth_gradient function")
![alt text](images/Booth_0.png "Booth_0")
![alt text](images/Booth_1.png "Booth_1")

![alt text](images/McCormick.png "Mccormick function")
![alt text](images/McCormick_gradient.png "Mccormick_gradient function")
![alt text](images/McCormick_0.png "Mccormick_0")
![alt text](images/McCormick_1.png "Mccormick_1")

![alt text](images/sgld.png "sgld")
